{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(versi 3) Kegiatan Modul 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "06V87X5rVRM2",
        "-muSoJjnFt8y",
        "fLoYIWSbKgko",
        "UxLpoRM6i6SV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radityajs28/Praktikum-ML/blob/main/(versi_3)_Kegiatan_Modul_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQBa4hXoxDUd"
      },
      "source": [
        "# **Soal Praktikum Overfitting Handling #1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06V87X5rVRM2"
      },
      "source": [
        "## Kegiatan 1 **(Individu)** \n",
        "70 poin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6kTqqtESNnc"
      },
      "source": [
        "**Peraturan :**\n",
        "* Tidak boleh ada error dalam kode program\n",
        "* Dalam modul ini tidak diperbolehkan menggunakan teknik transfer learning dari pretrain model baik yang telah dibangun sendiri atau anda dapatkan dari sumber lain (tensorflow, keras, dan sebagainya)\n",
        "* Perhatikan langkah demi langkah yang diperintahkan dalam kegiatan ini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muSoJjnFt8y"
      },
      "source": [
        "### Pengenalan tugas kegiatan 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxFmKc3D1apX"
      },
      "source": [
        "Dataset yang akan anda gunakan dalam kegiatan ini adalah dataset [Rock Paper Scissors](https://www.kaggle.com/drgfreeman/rockpaperscissors).  Demi mempermudah anda dalam mengerjakan modul ini maka akan sangat disarankan untuk menggunakan [google colab](https://colab.research.google.com/). Anda dapat menggunakan google colab untuk mendownload langsung dataset dari kaggle dan menyimpannya dalam google drive anda. Untuk kenyamanan dan ruang kerja yang besar akan lebih baik anda menggunakan email kampus untuk menyimpan dataset yang anda gunakan. Perhatikan langkah berikut untuk melakukan setting environment anda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLoYIWSbKgko"
      },
      "source": [
        "### 1. Initial process\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yzN1yOK1V-K"
      },
      "source": [
        "* Mount drive terlebih dahulu\n",
        "\n",
        "* Untuk dapat mengakses dataset ini anda diharuskan memiliki akun kaggle. Jika belum memilikinya buat satu akun pribadi.\n",
        "\n",
        "* Download kaggle API.json kemudian upload dalam google drive anda.\n",
        "\n",
        "* Ubah lokasi direktori kerja anda ke direktori dimana anda menyimpan kaggle.json\n",
        "\n",
        "* Buka laman dataset kemudian Copy API Command.\n",
        "\n",
        "* Jalankan perintah untuk mendownload dataset dari kaggle menggunakan google colab.\n",
        "\n",
        "* Gunakan tutorial berikut untuk lebih jelasnya : [Fetch Kaggle Dataset into Google Colab](https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a)\n",
        "\n",
        "* Untuk selanjutnya pahami code dibawah dengan baik."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iP7_H-5ubtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c5536d-9699-4cad-dfb0-44bae65e7960"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWkAcnefSPKI"
      },
      "source": [
        "# Definisikan path kaggle json\n",
        "# Sesuaikan dengan path anda\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/DATASETS\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUJ-XM5S4Th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7274f73e-0b9a-4aab-d3d6-397b43463620"
      },
      "source": [
        "# Ubah lokasi direktori kerja\n",
        "# Sesuaikan dengan path anda\n",
        "%cd /content/drive/My Drive/DATASETS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DATASETS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Bbmd-TCGhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bdd8263-554b-41f8-cb68-af6182a9025b"
      },
      "source": [
        "# Cek apakah api sudah terbaca oleh sistem\n",
        "!ls  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset  kaggle.json  test  train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wGGZC8vTX0A"
      },
      "source": [
        "* Paste API Command dari kaggle dataset yang telah anda copy sebelumnya dan tambahkan tanda seru didepannya.\n",
        "* Pastikan anda menggunakan akun google dari kampus untuk mendapatkan storage penyimpanan unlimited.\n",
        "* Lebih disarankan untuk menggunakan google colab karena proses download data lebih cepat dan stabil daripada download manual dan menggunakan jupyter notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emSTR53KTGW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc3929b-2069-4cd2-97ab-a4a382de6b8c"
      },
      "source": [
        "!kaggle datasets download -d drgfreeman/rockpaperscissors"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rockpaperscissors.zip to /content/drive/My Drive/dataset\n",
            " 99% 303M/306M [00:03<00:00, 88.3MB/s]\n",
            "100% 306M/306M [00:03<00:00, 88.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcpagHVWbdDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8c2783-4d09-487a-8708-1e3a63b4e813"
      },
      "source": [
        "# Cek isi direktori kerja dan memastikan dataset telah berhasil didownload.\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  rockpaperscissors.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HDyNsR3bam4"
      },
      "source": [
        "# Ekstrak file dataset dan hapus file zip dataset agar tidak memakan banyak tempat.\n",
        "!unzip \\*.zip &> /dev/null && rm *.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgw_k1zihmkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d1f1a2-5138-4da3-a7f1-a244e273a89a"
      },
      "source": [
        "# Cek isi direktori kerja untuk memastikan dataset telah berhasil diekstrak.\n",
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  paper  README_rpc-cv-images.txt  rock  rps-cv-images  scissors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPVmxstVUvyL"
      },
      "source": [
        "Buat folder baru bernama `dataset` dan memindahkan folder `paper, rock, scissors` kedalam folder `dataset`. Selanjutnya, lakukan splitting dataset menjadi 3 bagian `train, test, val` dan simpan ketiga folder tersebut diluar folder `dataset`. Data `train dan val` akan digunakan ketika anda melakukan training model. Dan data `test` akan anda gunakan ketika anda melakukan prediksi unseen data menggunakan model yang telah anda latih.\n",
        "\n",
        "*Ingat google colab juga menerima command berbasis linux.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbsMEBpr9CcC"
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmGBjWnN9GkE"
      },
      "source": [
        "!mv -t dataset paper rock scissors"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9RtG0W9UXq"
      },
      "source": [
        "!mkdir train\n",
        "!mkdir test\n",
        "!mkdir val"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5jaU1Ey91jr"
      },
      "source": [
        "!rm -rf rps-cv-images\n",
        "!rm *.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAIkqB1wdrvk"
      },
      "source": [
        "import os\n",
        "kertas = os.listdir('/content/drive/MyDrive/DATASETS/dataset/paper')\n",
        "batu = os.listdir('/content/drive/MyDrive/DATASETS/dataset/rock')\n",
        "gunting = os.listdir('/content/drive/MyDrive/DATASETS/dataset/scissors')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ysJ4iLebSS",
        "outputId": "9e966081-17f8-4409-eec9-edffa4de7174"
      },
      "source": [
        "print('kertas :' + str(len(kertas)))\n",
        "print('batu :' + str(len(batu)))\n",
        "print('gunting :' + str(len(gunting)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kertas :712\n",
            "batu :726\n",
            "gunting :750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EesF_Kn42Zy3",
        "outputId": "4db7f40f-07c1-443a-88c9-8bca1ab88ac6"
      },
      "source": [
        "!mkdir batuguntingkertas\n",
        "!mv -t batuguntingkertas test train val"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘batuguntingkertas’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FpRoyQN28ZG",
        "outputId": "c0bd28fa-eb97-4687-e2c0-b90f4ec940fd"
      },
      "source": [
        "!ls batuguntingkertas"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXQsF9cp3Et_"
      },
      "source": [
        "base_dir = '/content/drive/MyDrive/DATASETS/batuguntingkertas'\n",
        "data_dir = '/content/drive/MyDrive/DATASETS/dataset'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efjT-1Y01C7I",
        "outputId": "2b615eac-2397-4809-bc02-9292a34347a5"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7isREWv32OY",
        "outputId": "98fdeaa0-e4db-4422-f184-95675597633a"
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(data_dir, output=base_dir, seed=1337, ratio=(.7,.15,.15), group_prefix=None)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2188 files [09:45,  3.74 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N61YblHq67Sq"
      },
      "source": [
        "tr_kertas = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/train/paper')\n",
        "tr_batu = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/train/rock')\n",
        "tr_gunting = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/train/scissors')\n",
        "\n",
        "ts_kertas = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/test/paper')\n",
        "ts_batu = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/test/rock')\n",
        "ts_gunting = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/test/scissors')\n",
        "\n",
        "val_kertas = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/val/paper')\n",
        "val_batu = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/val/rock')\n",
        "val_gunting = os.listdir('/content/drive/MyDrive/DATASETS/batuguntingkertas/val/scissors')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aeta9U77iD2",
        "outputId": "a7521796-9ab8-4451-85cc-ab80c63a91cd"
      },
      "source": [
        "print('train kertas :' + str(len(tr_kertas)))\n",
        "print('train batu :' + str(len(tr_batu)))\n",
        "print('train gunting :' + str(len(tr_gunting)))\n",
        "\n",
        "print('test kertas :' + str(len(ts_kertas)))\n",
        "print('test batu :' + str(len(ts_batu)))\n",
        "print('test gunting :' + str(len(ts_gunting)))\n",
        "\n",
        "print('val kertas :' + str(len(val_kertas)))\n",
        "print('val batu :' + str(len(val_batu)))\n",
        "print('val gunting :' + str(len(val_gunting)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train kertas :498\n",
            "train batu :508\n",
            "train gunting :525\n",
            "test kertas :108\n",
            "test batu :110\n",
            "test gunting :113\n",
            "val kertas :106\n",
            "val batu :108\n",
            "val gunting :112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxLpoRM6i6SV"
      },
      "source": [
        "### 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJHBci_m0vKy"
      },
      "source": [
        "Kita anggap dataset yang kita miliki merupakan dataset yang telah bersih dan siap digunakan untuk proses training model. Namun agar data yang kita miliki dapat diproses oleh model maka kita perlu melakukan sedikit proses augmentasi sederhana. \n",
        "\n",
        "**NOTE :** Penjelasan augmentasi secara detail akan dibahas pada modul selanjutnya. Disini kita akan mengunakan augmentasi sederhana saja seperti resize, flip dan rotation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxkE0duhmOt4"
      },
      "source": [
        "Lakukan proses agumentasi sederhana pada dataset anda menggunakan `ImageDataGenerator` dengan ketentuan melakukan proses seperti berikut :\n",
        "\n",
        "* Resize\n",
        "* Rescaling\n",
        "* Color Mode\n",
        "* Shuffle\n",
        "* Class Mode\n",
        "\n",
        "Terapkan semua proses diatas pada data `train, test dan validation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga4Hz63e2bpl"
      },
      "source": [
        "# TULIS KODE ANDA DISINI\n",
        "train_path = os.path.join(base_dir,'train')\n",
        "test_path = os.path.join(base_dir,'test')\n",
        "val_path = os.path.join(base_dir,'val')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVp_98ey8vpS",
        "outputId": "8674b1a9-9751-42fa-f843-163048aefa4a"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "Batch_size=32\n",
        "augmen_gen = ImageDataGenerator(rescale=1. /255,\n",
        "                                rotation_range=40,\n",
        "                                width_shift_range=0.2,\n",
        "                                height_shift_range=0.2,\n",
        "                                zoom_range=0.2,\n",
        "                                horizontal_flip=True,\n",
        "                                fill_mode='nearest')\n",
        "\n",
        "train_gen = augmen_gen.flow_from_directory(\n",
        "    train_path,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        "    target_size = (224,224),\n",
        "    batch_size = Batch_size,\n",
        "    color_mode = 'rgb'\n",
        ")\n",
        "\n",
        "val_gen = augmen_gen.flow_from_directory(\n",
        "    val_path,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        "    target_size = (224,224),\n",
        "    batch_size = Batch_size,\n",
        "    color_mode = 'rgb'\n",
        ")\n",
        "\n",
        "test_gen = augmen_gen.flow_from_directory(\n",
        "    test_path,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle=True,\n",
        "    target_size = (224,224),\n",
        "    batch_size = Batch_size,\n",
        "    color_mode = 'rgb'\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1531 images belonging to 3 classes.\n",
            "Found 326 images belonging to 3 classes.\n",
            "Found 331 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNr_kRbxyZYT"
      },
      "source": [
        "### 3. Definisikan Model CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I939-GX0qsZ"
      },
      "source": [
        "Bangun model CNN dan lakukan evaluasi sesuai kriteria **WAJIB** berikut:\n",
        "\n",
        "* Menerapkan proses Convolution \n",
        "* Menerapkan proses Pooling\n",
        "* Menerapkan Dropout\n",
        "* Menerpakan BatchNormalization\n",
        "* Evaluasi model menggunakan grafik loss dan accuracy\n",
        "* Evaluasi menggunakan classification report\n",
        "* Evaluasi menggunakan confusion matrix\n",
        "* Pastikan nilai akurasi model > 80%\n",
        "* Mendefinisikan minimal 100 epoch untuk masing-masing model\n",
        "* Melakukan prediksi minimal 15 gambar acak yang dapat mewakili seluruh kelas\n",
        "* Menampilkan input gambar yang di prediksi beserta label hasil prediksi, nilai akurasi prediksi, dan lama waktu prediksi dalam sebuah plot. (15 gambar ditampilkan dalam 1 plot)\n",
        "* Save model dalam file `json` dan simpan bobot dalam file `HDF5`\n",
        "* Pastikan model anda dapat memprediksi unseen data dengan benar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BwlkwcO2fpf"
      },
      "source": [
        "# TULIS KODE ANDA DISINI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zzfYOy8U4TX"
      },
      "source": [
        "## Kegiatan 2 **(berkelompok)**\n",
        "30 poin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuUCK4qcEp97"
      },
      "source": [
        "**Ketentuan Wajib**\n",
        "* Tulis dokumentasi tugas kelompok anda dalam file README.md\n",
        "* Cek daftar dataset seluruh praktikan [disini](https://docs.google.com/spreadsheets/d/1qyu5AVDhPhegpRTbNaDoq5qXX4_CX09Q7tYyD-fkF_c/edit?usp=sharing)\n",
        "* Seluruh data dan progress pengerjaan tugas kelompok harus berada dalam github repository sebelum praktikum dimulai\n",
        "* Tidak diperbolehkan berganti anggota kelompok selama satu semester ini\n",
        "* Tidak diperbolehkan berganti repository selama mengerjakan tugas kelompok ini\n",
        "* **Tidak diperbolehkan berganti dataset atau jurnal rujukan**\n",
        "* Pastikan anda menggunakan akun github pribadi untuk melakukan commit dan push\n",
        "\n",
        "**Penilaian**\n",
        "* Keaktifan dalam tim\n",
        "* Kontribusi dalam proyek dan tim\n",
        "* Penerapan prinsip kerja Agile (sprint backlog dan report terdokumentasikan dengan baik)\n",
        "* Progress pengerjaan tugas kelompok\n",
        "* Pemahaman masing-masing anggota tim terhadap tugas yang dikerjakan\n",
        "* Pendokumentasian proyek \"clear and clean documentation\"\n",
        "\n",
        "**Materi pendukung**\n",
        "* [Project documentation](https://realpython.com/documenting-python-code)\n",
        "* [Github readme](https://docs.github.com/en/github/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)\n",
        "* [Sprint backlog](https://www.lucidchart.com/blog/how-to-develop-a-product-backlog-in-agile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8-XbSmMp0NT"
      },
      "source": [
        "**Tugas**\n",
        "\n",
        "Melanjutkan tugas kelompok di modul 1 & 2 sekarang kerjakan beberapa poin berikut untuk didemokan kepada asisten masing-masing.\n",
        "\n",
        "*   Melakukan proses preprocessing dataset dengan ketentuan:\n",
        " * augmentasi data menggunakan ImageDataGenerator\n",
        " * splitting dataset menjadi (75% train, 14% validation, 1% test)\n",
        "*   Melakukan training beberapa skema model menggunakan model CNN sederhana buatan sendiri **(minimal 2 model)** *tidak diperbolehkan menggunakan transfer learning* \n",
        " * Menerapkan proses Convolution\n",
        " * Menerapkan proses Pooling\n",
        " * Menerapkan Dropout\n",
        " * Menerpakan BatchNormalization\n",
        " * Model dengan beberapa variasi learning rate\n",
        " * Minimal 100 epoch per model\n",
        "* Menyimpan model yang telah di training kedalam file `.h5` [Lihat disini](https://www.tensorflow.org/tutorials/keras/save_and_load)\n",
        "*  Mencatat hasil perkembangan tugas kelompok dalam file `sprint_project.xlsx` tandai masing-masing task dengan status **Done** *untuk task yang telah selesai dikerjakan*, **On Going** *untuk task yang dalam proses pengerjaan*, **Waiting** *untuk task yang belum atau akan dikerjakan*\n",
        "* Pastikan anda menulis tanggal mulai dan tanggal selesai masing-masing task dengan benar\n",
        "* Pastikan anda menulis penanggung jawab masing-masing task (Penanggung jawab bertugas menyelesaikan dan menuntaskan masing-masing task yang diberikan)\n",
        "* `commit` dan `push` seluruh perkerjaan yang anda lakukan kedalam branch pribadi dalam repository tugas kelompok yang telah anda buat sebelumnya.\n",
        "* Presentasikan kepada asisten tentang apa yang anda lakukakan selama mengerjakan tugas kelompok ini. Ceritakan tentang tugas masing-masing anggota,  kendala dalam mengerjakan tugas sampai solusi yang anda lakukan saat mengerjakan tugas kelompok ini.\n",
        "\n"
      ]
    }
  ]
}